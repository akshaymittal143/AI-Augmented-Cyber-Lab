# AI-Augmented Cyber Lab Environment Configuration
# Copy this file to .env and update the values as needed

# =============================================================================
# REQUIRED: AI Model Configuration
# =============================================================================
# Get your API key from OpenAI: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-actual-openai-api-key-here

# Optional: Anthropic API for alternative models
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Model settings (defaults shown)
LLM_MODEL=gpt-4
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=2048

# =============================================================================
# Database Configuration
# =============================================================================
# PostgreSQL for persistent storage
DATABASE_URL=postgresql://user:password@localhost:5432/cyber_lab

# Redis for caching and session management
REDIS_URL=redis://localhost:6379/0

# =============================================================================
# Security Settings
# =============================================================================
# REQUIRED: Generate a secure random key (use: python -c "import secrets; print(secrets.token_hex(32))")
SECRET_KEY=your-secure-secret-key-here
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=30

# =============================================================================
# Kubernetes Configuration
# =============================================================================
# Path to your kubeconfig file
KUBECONFIG_PATH=~/.kube/config

# Kubernetes namespace for deployment
NAMESPACE=ai-cyber-lab

# Cluster name for identification
CLUSTER_NAME=cyber-lab-cluster

# =============================================================================
# Lab Capacity and Behavior
# =============================================================================
# Maximum number of students per lab session
MAX_STUDENTS_PER_LAB=50

# Session timeout in minutes
SESSION_TIMEOUT_MINUTES=60

# Cooldown period between hints in seconds
HINT_COOLDOWN_SECONDS=30

# =============================================================================
# Development Settings
# =============================================================================
# Enable debug mode (set to false in production)
DEBUG=true

# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# =============================================================================
# Monitoring and Observability
# =============================================================================
# Prometheus metrics endpoint
PROMETHEUS_ENDPOINT=http://localhost:9090

# Jaeger tracing endpoint
JAEGER_ENDPOINT=http://localhost:14268/api/traces

# =============================================================================
# External Services
# =============================================================================
# GitHub API for repository access (optional)
GITHUB_TOKEN=your-github-token-here

# Docker Hub credentials (optional)
DOCKER_USERNAME=your-docker-username
DOCKER_PASSWORD=your-docker-password

# =============================================================================
# Evaluation and Testing
# =============================================================================
# Path to evaluation datasets
EVALUATION_DATASET_PATH=./datasets/

# Path to model checkpoints
MODEL_CHECKPOINT_PATH=./models/

# Enable evaluation mode
EVALUATION_MODE=false

# =============================================================================
# Feature Flags
# =============================================================================
# Enable threat simulation
ENABLE_THREAT_SIMULATION=true

# Enable RL hint agent
ENABLE_RL_AGENT=true

# Enable LLM analyzer
ENABLE_LLM_ANALYZER=true

# Enable expert evaluation interface
ENABLE_EXPERT_EVALUATION=false

# =============================================================================
# Performance Tuning
# =============================================================================
# Number of worker processes
WORKER_PROCESSES=4

# Request timeout in seconds
REQUEST_TIMEOUT=30

# Maximum concurrent requests
MAX_CONCURRENT_REQUESTS=100

# =============================================================================
# Backup and Recovery
# =============================================================================
# Enable automatic backups
ENABLE_BACKUPS=true

# Backup frequency in hours
BACKUP_FREQUENCY_HOURS=24

# Backup retention days
BACKUP_RETENTION_DAYS=30

# =============================================================================
# Notes
# =============================================================================
# 1. You MUST set OPENAI_API_KEY to use the LLM analyzer functionality
# 2. Generate a secure SECRET_KEY for production deployments
# 3. Update database credentials for your environment
# 4. Configure Kubernetes settings for your cluster
# 5. Adjust capacity settings based on your infrastructure
# 6. Set DEBUG=false and use appropriate LOG_LEVEL for production
